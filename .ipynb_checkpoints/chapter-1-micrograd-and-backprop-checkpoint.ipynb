{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9e3dc448-6f4e-4cae-9bea-192395970802",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value(data=3.140592653839794)\n"
     ]
    }
   ],
   "source": [
    "import collections\n",
    "import math\n",
    "\n",
    "class Value:\n",
    "    # `Value` represents, ahem, a value with some additional information\n",
    "    # for backpropagation to work\n",
    "    def __init__(self, data, depends_on=None):\n",
    "        if depends_on is None:\n",
    "            depends_on = []\n",
    "            \n",
    "        self.data = data\n",
    "        self.grad = 0\n",
    "        self.depends_on = depends_on\n",
    "        self._backward = []\n",
    "\n",
    "    def __add__(self, other):\n",
    "        other = Value.ensure(other)\n",
    "        res = Value(\n",
    "            data=self.data + other.data,\n",
    "            depends_on=[self, other],\n",
    "        )\n",
    "        self.add_backward(lambda: res.grad)\n",
    "        other.add_backward(lambda: res.grad)\n",
    "        return res\n",
    "\n",
    "\n",
    "    def __sub__(self, other):\n",
    "        other = Value.ensure(other)\n",
    "        res = Value(\n",
    "            self.data - other.data,\n",
    "            depends_on=[self, other],\n",
    "        )\n",
    "        self.add_backward(lambda: res.grad)\n",
    "        other.add_backward(lambda: -res.grad)\n",
    "        return res\n",
    "\n",
    "    def __mul__(self, other):\n",
    "        other = Value.ensure(other)\n",
    "        res = Value(\n",
    "            self.data * other.data,\n",
    "            depends_on=[self, other],\n",
    "        )\n",
    "        self.add_backward(lambda: res.grad * other.data)\n",
    "        other.add_backward(lambda: res.grad * self.data)\n",
    "        return res\n",
    "\n",
    "    def __truediv__(self, other):\n",
    "        other = Value.ensure(other)\n",
    "        res = Value(\n",
    "            self.data / other.data,\n",
    "            depends_on=[self, other],\n",
    "        )\n",
    "        self.add_backward(lambda: res.grad / other.data)\n",
    "        other.add_backward(lambda: res.grad * -self.data / (other.data ** 2))\n",
    "        return res\n",
    "\n",
    "    def __pow__(self, other):\n",
    "        try:\n",
    "            self.data ** other\n",
    "        except OverflowError:\n",
    "            print(f'{self.data=}, {other=}')\n",
    "        res = Value(\n",
    "            self.data ** other,\n",
    "            depends_on=[self],\n",
    "        )\n",
    "        self.add_backward(lambda: res.grad * other * (self.data ** (other - 1)))\n",
    "        return res\n",
    "\n",
    "    def tanh(self):\n",
    "        p = 2 * self.data\n",
    "        res = Value(\n",
    "            (math.exp(p) - 1) / (math.exp(p) + 1),\n",
    "            depends_on=[self]\n",
    "        )\n",
    "        self.add_backward(lambda: res.grad * (1 - res.data ** 2))\n",
    "        return res\n",
    "    \n",
    "    def backward(self):\n",
    "        self.grad = 1\n",
    "        for node in self._iter_topo_sort():\n",
    "            if node is self:\n",
    "                continue\n",
    "            node.calc_gradient()\n",
    "            \n",
    "    def calc_gradient(self):\n",
    "        for f in self._backward:\n",
    "            self.grad += f()\n",
    "        \n",
    "    def _iter_topo_sort(self):\n",
    "        visited = set()\n",
    "        nodes = [self]\n",
    "        in_degrees = collections.Counter({self: 0})\n",
    "        while nodes:\n",
    "            node = nodes.pop()\n",
    "            for dep in node.depends_on:\n",
    "                in_degrees[dep] += 1\n",
    "                if dep not in visited:\n",
    "                    visited.add(dep)\n",
    "                    nodes.append(dep)\n",
    "        queue = [node for (node, count) in in_degrees.items() if count == 0]\n",
    "        assert queue, \"can't toposort graph with cycle\"\n",
    "        while queue:\n",
    "            new_queue = []\n",
    "            for node in queue:\n",
    "                yield node\n",
    "                for dep in node.depends_on:\n",
    "                    in_degrees[dep] -= 1\n",
    "                    if in_degrees[dep] == 0:\n",
    "                        new_queue.append(dep)\n",
    "            queue = new_queue\n",
    "            \n",
    "    def add_backward(self, f):\n",
    "        self._backward.append(f)\n",
    "\n",
    "    def __radd__(self, other):\n",
    "        return self + other\n",
    "\n",
    "    def __rsub__(self, other):\n",
    "        return -self + other\n",
    "\n",
    "    def __rmul__(self, other):\n",
    "        return self * other\n",
    "\n",
    "    def __rtruediv__(self, other):\n",
    "        return (self ** -1) * other\n",
    "\n",
    "    def __neg__(self):\n",
    "        return self * -1\n",
    "    \n",
    "    def zero_grad(self):\n",
    "        self.grad = 0\n",
    "        self._backward = []\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f'Value(data={self.data})'\n",
    "\n",
    "    @staticmethod\n",
    "    def ensure(data):\n",
    "        if isinstance(data, (int, float)):\n",
    "            return Value(data)\n",
    "        assert isinstance(data, Value), f'{data=} should be an instance of Value'\n",
    "        return data\n",
    "\n",
    "\n",
    "def test_value_operations():\n",
    "    # calculate pi using Leibniz formula\n",
    "    pi = Value(0.0)  \n",
    "    for i in range(1000):\n",
    "        if i % 2 == 0:\n",
    "            delta = 1.0 / (2 * i + 1)\n",
    "        else:\n",
    "            delta = -Value(1.0) / (Value(2) * Value(i) + Value(1))\n",
    "        pi += delta\n",
    "    pi *= 4\n",
    "    print(pi)\n",
    "    assert math.isclose(pi.data, math.pi, rel_tol=0.001)\n",
    "\n",
    "\n",
    "test_value_operations()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "5030eb5b-5d4e-4b1a-9dce-76ae1d3578cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Value(data=-1.8746015426384717)]\n",
      "loss=Value(data=12457.91064888493)\n",
      "ys=[93, 98, 103, 108, 113, 118, 123, 128, 133, 138]\n",
      "pred_ys=[Value(data=0.0), Value(data=0.9953896308891226), Value(data=1.9907792617782452), Value(data=2.9861688926673677), Value(data=3.9815585235564903), Value(data=4.976948154445613), Value(data=5.9723377853347355), Value(data=6.967727416223858), Value(data=7.963117047112981), Value(data=8.958506678002102)]\n",
      "\n",
      "loss=Value(data=0.0283021821169566)\n",
      "ys=[93, 98, 103, 108, 113, 118, 123, 128, 133, 138]\n",
      "pred_ys=[Value(data=92.68735459345281), Value(data=97.7372136360279), Value(data=102.78707267860301), Value(data=107.8369317211781), Value(data=112.8867907637532), Value(data=117.93664980632829), Value(data=122.9865088489034), Value(data=128.0363678914785), Value(data=133.0862269340536), Value(data=138.1360859766287)]\n",
      "\n",
      "loss=Value(data=3.410022354112321e-07)\n",
      "ys=[93, 98, 103, 108, 113, 118, 123, 128, 133, 138]\n",
      "pred_ys=[Value(data=92.9989147727141), Value(data=97.99908783904522), Value(data=102.99926090537633), Value(data=107.99943397170745), Value(data=112.99960703803856), Value(data=117.99978010436968), Value(data=122.99995317070079), Value(data=128.0001262370319), Value(data=133.00029930336302), Value(data=138.00047236969414)]\n",
      "\n",
      "loss=Value(data=4.108606344302386e-12)\n",
      "ys=[93, 98, 103, 108, 113, 118, 123, 128, 133, 138]\n",
      "pred_ys=[Value(data=92.99999623305432), Value(data=97.99999683378698), Value(data=102.99999743451963), Value(data=107.99999803525228), Value(data=112.99999863598494), Value(data=117.9999992367176), Value(data=122.99999983745025), Value(data=128.0000004381829), Value(data=133.00000103891557), Value(data=138.00000163964822)]\n",
      "\n",
      "loss=Value(data=4.950326368462564e-17)\n",
      "ys=[93, 98, 103, 108, 113, 118, 123, 128, 133, 138]\n",
      "pred_ys=[Value(data=92.99999998692448), Value(data=97.9999999890097), Value(data=102.99999999109491), Value(data=107.99999999318013), Value(data=112.99999999526534), Value(data=117.99999999735056), Value(data=122.99999999943577), Value(data=128.000000001521), Value(data=133.0000000036062), Value(data=138.00000000569142)]\n",
      "\n",
      "loss=Value(data=5.9647305327183e-22)\n",
      "ys=[93, 98, 103, 108, 113, 118, 123, 128, 133, 138]\n",
      "pred_ys=[Value(data=92.99999999995461), Value(data=97.99999999996184), Value(data=102.99999999996909), Value(data=107.99999999997632), Value(data=112.99999999998357), Value(data=117.9999999999908), Value(data=122.99999999999804), Value(data=128.0000000000053), Value(data=133.0000000000125), Value(data=138.00000000001975)]\n",
      "\n",
      "loss=Value(data=4.300289053638714e-25)\n",
      "ys=[93, 98, 103, 108, 113, 118, 123, 128, 133, 138]\n",
      "pred_ys=[Value(data=92.99999999999878), Value(data=97.99999999999898), Value(data=102.99999999999916), Value(data=107.99999999999936), Value(data=112.99999999999955), Value(data=117.99999999999974), Value(data=122.99999999999994), Value(data=128.0000000000001), Value(data=133.0000000000003), Value(data=138.0000000000005)]\n",
      "\n",
      "loss=Value(data=4.300289053638714e-25)\n",
      "ys=[93, 98, 103, 108, 113, 118, 123, 128, 133, 138]\n",
      "pred_ys=[Value(data=92.99999999999878), Value(data=97.99999999999898), Value(data=102.99999999999916), Value(data=107.99999999999936), Value(data=112.99999999999955), Value(data=117.99999999999974), Value(data=122.99999999999994), Value(data=128.0000000000001), Value(data=133.0000000000003), Value(data=138.0000000000005)]\n",
      "\n",
      "loss=Value(data=4.300289053638714e-25)\n",
      "ys=[93, 98, 103, 108, 113, 118, 123, 128, 133, 138]\n",
      "pred_ys=[Value(data=92.99999999999878), Value(data=97.99999999999898), Value(data=102.99999999999916), Value(data=107.99999999999936), Value(data=112.99999999999955), Value(data=117.99999999999974), Value(data=122.99999999999994), Value(data=128.0000000000001), Value(data=133.0000000000003), Value(data=138.0000000000005)]\n",
      "\n",
      "loss=Value(data=4.300289053638714e-25)\n",
      "ys=[93, 98, 103, 108, 113, 118, 123, 128, 133, 138]\n",
      "pred_ys=[Value(data=92.99999999999878), Value(data=97.99999999999898), Value(data=102.99999999999916), Value(data=107.99999999999936), Value(data=112.99999999999955), Value(data=117.99999999999974), Value(data=122.99999999999994), Value(data=128.0000000000001), Value(data=133.0000000000003), Value(data=138.0000000000005)]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "\n",
    "def pairwise(iterable):\n",
    "    prev = None\n",
    "    for i, item in enumerate(iterable):\n",
    "        if i != 0:\n",
    "            yield prev, item    \n",
    "        prev = item\n",
    "\n",
    "\n",
    "class Neuron:\n",
    "    def __init__(self, input_size):\n",
    "        self.weights = [Value(random.uniform(-1.0, 1.0)) for _ in range(input_size)]\n",
    "        self.bias = Value(0)\n",
    "\n",
    "    def __call__(self, input_):\n",
    "        return sum((x * w for (x, w) in zip(input_, self.weights)), self.bias)\n",
    "\n",
    "    def parameters(self):\n",
    "        return [*self.weights, self.bias]\n",
    "\n",
    "\n",
    "class Layer:\n",
    "    def __init__(self, input_size, output_size):\n",
    "        self.neurons = [Neuron(input_size) for _ in range(output_size)]\n",
    "\n",
    "    def __call__(self, input_):\n",
    "        return [n(input_) for n in self.neurons]\n",
    "\n",
    "    def parameters(self):\n",
    "        return [p for neuron in self.neurons for p in neuron.parameters()]\n",
    "\n",
    "\n",
    "class MLP:\n",
    "    def __init__(self, input_size, layer_sizes):\n",
    "        assert layer_sizes\n",
    "        self.layers = []\n",
    "        sizes = [input_size, *layer_sizes]\n",
    "        for layer_input_size, layer_output_size in pairwise(sizes):\n",
    "            self.layers.append(Layer(layer_input_size, layer_output_size))\n",
    "\n",
    "    def __call__(self, input_):\n",
    "        x = input_\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "        return x\n",
    "\n",
    "    def parameters(self):\n",
    "        return [p for layer in self.layers for p in layer.parameters()]\n",
    "\n",
    "\n",
    "def calc_loss(pred_ys, ys):\n",
    "    return sum((py - y) ** 2 for py, y in zip(pred_ys, ys)) / len(ys)\n",
    "\n",
    "\n",
    "def item(x):\n",
    "    assert len(x) == 1\n",
    "    return x[0]\n",
    "\n",
    "\n",
    "def test_mlp():\n",
    "    mlp = MLP(1, (4, 9, 10, 1))\n",
    "    print(mlp([1, 2, 3]))\n",
    "\n",
    "\n",
    "def test_grad():\n",
    "    x = Value(3.0)\n",
    "    y = Value(4.0)\n",
    "    for i in range(2):\n",
    "        x.zero_grad()\n",
    "        y.zero_grad()\n",
    "        z = x * y\n",
    "        z.backward()\n",
    "        assert x.grad == 4.0, f'{i=}, {x.grad=}'\n",
    "        assert y.grad == 3.0, f'{i=}, {y.grad=}'\n",
    "        assert z.grad == 1.0, f'{i=}, {z.grad=}'\n",
    "\n",
    "\n",
    "def test_mlp_training():\n",
    "    xs = range(10)\n",
    "    ys = [(5 * x + 93) for x in xs]\n",
    "    mlp = MLP(1, (1,))\n",
    "    num_iter = 10000\n",
    "    learning_rate = 1e-2\n",
    "    # gradient descent\n",
    "    for i in range(num_iter):\n",
    "        for p in mlp.parameters():\n",
    "            p.zero_grad()\n",
    "        pred_ys = [item(mlp([x])) for x in xs]\n",
    "        loss = calc_loss(pred_ys, ys)\n",
    "        loss.backward()\n",
    "        for p in mlp.parameters():\n",
    "            p.data -= learning_rate * p.grad\n",
    "        if i % 1000 == 0:\n",
    "            print(f'{loss=}\\n{ys=}\\n{pred_ys=}\\n')\n",
    "\n",
    "test_grad()\n",
    "test_mlp()\n",
    "test_mlp_training()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0837749-2dfc-4738-8000-ab843f171140",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
